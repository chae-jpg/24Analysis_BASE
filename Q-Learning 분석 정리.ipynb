{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf2f5ed",
      "metadata": {
        "id": "acf2f5ed"
      },
      "outputs": [],
      "source": [
        "# (1) 첨부된 code에서 Q-Learning이 어떻게 적용되었는지 정리해보세요!\n",
        "# (2) 코드에서 gamma 값을 0.5 또는 0.99로 바꾸어 실행해보고, gamma 값을 다르게 설정하면 Q-matrix가 어떻게 변하는지 비교하여 정리해보세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d5fe3409",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5fe3409",
        "outputId": "ef4298e3-5884-4855-acb2-afcf5170b8fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  0.  0. -1.  0.]\n",
            " [ 0. 10.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[  0. -10.   0.  -1.   0.]\n",
            " [  0.  10.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.]]\n",
            "Q-matrix is updated\n",
            "[[  0. -10.   0.  -1.   0.]\n",
            " [  0.  10.   0.   0.   0.]\n",
            " [  0.   0.   0.  10.   0.]\n",
            " [  0.   0.   0.   0.   0.]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[  0. -10.   0.  -1.  -1.]\n",
            " [  0.  10.   0.   0.   0.]\n",
            " [  0.   0.   0.  10.   0.]\n",
            " [  0.   0.   0.   0.   0.]]\n",
            "Q-matrix is updated\n",
            "[[  0. -10.   0.   7.  -1.]\n",
            " [  0.  10.   0.   0.   0.]\n",
            " [  0.   0.   0.  10.   0.]\n",
            " [  0.   0.   0.   0.   0.]]\n",
            "Q-matrix is updated\n",
            "[[  0. -10.   0.   7.  -1.]\n",
            " [  0.  10.   0.   0.   0.]\n",
            " [  0.   0.   0.  10.   0.]\n",
            " [  0.   0.   0.   0.   0.]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0. -2.  0.  7. -1.]\n",
            " [ 0. 10.  0.  0.  0.]\n",
            " [ 0.  0.  0. 10.  0.]\n",
            " [ 0.  0.  0.  0.  0.]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.  -1. ]\n",
            " [ 0.  10.   0.   0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.  -1. ]\n",
            " [ 0.  10.   0.   0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.  -1. ]\n",
            " [ 0.  10.   0.   0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.  -2.   0.   7.  -1. ]\n",
            " [ 0.  10.   0.   0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.  -1. ]\n",
            " [ 0.  10.   0.   0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.  -1. ]\n",
            " [ 0.  10.   0.   0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.  -1. ]\n",
            " [ 0.  10.   0.   0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   0.   0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   0.   0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "final q-matrix : \n",
            "[[ 0.  -2.   0.   7.   4.6]\n",
            " [ 0.  10.   4.6  0.   0. ]\n",
            " [ 4.6  0.   0.  10.   7. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gamma = 0.8\n",
        "\n",
        "#For matrices reward and q_matrix columns are in order (U, D, L, R, N)\n",
        "\n",
        "# here the states are 0, 1, 2, 3 for convenience\n",
        "# 0 is the startinf state\n",
        "# 1 is state to the right of 0\n",
        "# 2 is the snake-pit state\n",
        "# 3 is the treasure(goal state)\n",
        "\n",
        "reward = np.array([[0, -10, 0, -1, -1],\n",
        "         [0, 10, -1, 0, -1],\n",
        "         [-1, 0, 0, 10, -1],\n",
        "         [-1, 0, -10, 0, 10]])\n",
        "\n",
        "q_matrix = np.zeros((4,5))\n",
        "\n",
        "# -1 represent invalid transitions\n",
        "transition_matrix = np.array([[-1, 2, -1, 1, 0],\n",
        "                  [-1, 3, 0, -1, 1],\n",
        "                  [0, -1, -1, 3, 2],\n",
        "                  [1, -1, 2, -1, 3]])\n",
        "\n",
        "# for valid actions\n",
        "# encode up as 0, down as 1, left as 2, right as 3, no action as 4\n",
        "# the rows are the states\n",
        "valid_action = np.array([[1, 3, 4],\n",
        "             [1, 2, 4],\n",
        "             [0, 3, 4],\n",
        "             [0, 2, 4]])\n",
        "\n",
        "for i in range(10): # 10 episodes\n",
        "    start_state = 0\n",
        "    current_state = start_state\n",
        "    while current_state != 3:\n",
        "        action = random.choice(valid_action[current_state])\n",
        "        next_state = transition_matrix[current_state][action]\n",
        "        future_rewards =[]\n",
        "        for action_nxt in valid_action[next_state]:\n",
        "            future_rewards.append(q_matrix[next_state][action_nxt])\n",
        "        q_state = reward[current_state][action] + gamma*max(future_rewards)\n",
        "        q_matrix[current_state][action] = q_state\n",
        "        print(q_matrix)\n",
        "        print('Q-matrix is updated')\n",
        "        current_state = next_state\n",
        "        if current_state == 3:\n",
        "            print('goal state reached')\n",
        "\n",
        "print('final q-matrix : ')\n",
        "print(q_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gamma = 0.99\n",
        "\n",
        "#For matrices reward and q_matrix columns are in order (U, D, L, R, N)\n",
        "\n",
        "# here the states are 0, 1, 2, 3 for convenience\n",
        "# 0 is the startinf state\n",
        "# 1 is state to the right of 0\n",
        "# 2 is the snake-pit state\n",
        "# 3 is the treasure(goal state)\n",
        "\n",
        "reward = np.array([[0, -10, 0, -1, -1],\n",
        "         [0, 10, -1, 0, -1],\n",
        "         [-1, 0, 0, 10, -1],\n",
        "         [-1, 0, -10, 0, 10]])\n",
        "\n",
        "q_matrix = np.zeros((4,5))\n",
        "\n",
        "# -1 represent invalid transitions\n",
        "transition_matrix = np.array([[-1, 2, -1, 1, 0],\n",
        "                  [-1, 3, 0, -1, 1],\n",
        "                  [0, -1, -1, 3, 2],\n",
        "                  [1, -1, 2, -1, 3]])\n",
        "\n",
        "# for valid actions\n",
        "# encode up as 0, down as 1, left as 2, right as 3, no action as 4\n",
        "# the rows are the states\n",
        "valid_action = np.array([[1, 3, 4],\n",
        "             [1, 2, 4],\n",
        "             [0, 3, 4],\n",
        "             [0, 2, 4]])\n",
        "\n",
        "for i in range(10): # 10 episodes\n",
        "    start_state = 0\n",
        "    current_state = start_state\n",
        "    while current_state != 3:\n",
        "        action = random.choice(valid_action[current_state])\n",
        "        next_state = transition_matrix[current_state][action]\n",
        "        future_rewards =[]\n",
        "        for action_nxt in valid_action[next_state]:\n",
        "            future_rewards.append(q_matrix[next_state][action_nxt])\n",
        "        q_state = reward[current_state][action] + gamma*max(future_rewards)\n",
        "        q_matrix[current_state][action] = q_state\n",
        "        print(q_matrix)\n",
        "        print('Q-matrix is updated')\n",
        "        current_state = next_state\n",
        "        if current_state == 3:\n",
        "            print('goal state reached')\n",
        "\n",
        "print('final q-matrix : ')\n",
        "print(q_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvQjlV67k_jO",
        "outputId": "d4027ee2-6bd0-467d-c6e3-cbef440594db"
      },
      "id": "BvQjlV67k_jO",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0. -10.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.]]\n",
            "Q-matrix is updated\n",
            "[[  0. -10.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.  10.   0.]\n",
            " [  0.   0.   0.   0.   0.]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.  -0.1  0.   0.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]\n",
            " [ 0.   0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -0.1  0.   0.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]\n",
            " [ 0.   0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.  -0.1  0.  -1.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]\n",
            " [ 0.   0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -0.1  0.  -1.   0. ]\n",
            " [ 0.   0.   0.   0.  -1. ]\n",
            " [ 0.   0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -0.1  0.  -1.   0. ]\n",
            " [ 0.   0.  -1.   0.  -1. ]\n",
            " [ 0.   0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -0.1  0.  -1.  -1. ]\n",
            " [ 0.   0.  -1.   0.  -1. ]\n",
            " [ 0.   0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -0.1  0.  -1.  -1. ]\n",
            " [ 0.   0.  -1.   0.  -1. ]\n",
            " [ 0.   0.   0.  10.   0. ]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.  -0.1  0.  -1.  -1. ]\n",
            " [ 0.   0.  -1.   0.  -1. ]\n",
            " [ 0.   0.   0.  10.   8.9]\n",
            " [ 0.   0.   0.   0.   0. ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.    -1.    -1.   ]\n",
            " [ 0.     0.    -1.     0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.    -1.    -1.   ]\n",
            " [ 0.     0.    -1.     0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.    -1.    -1.   ]\n",
            " [ 0.    10.    -1.     0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.    -0.1    0.     8.9   -1.   ]\n",
            " [ 0.    10.    -1.     0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9   -1.   ]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9   -1.   ]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9   -1.   ]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9   -1.   ]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9   -1.   ]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9   -1.   ]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [-1.099  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.    -1.   ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.     8.9  ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.     8.9  ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.     8.9  ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.     8.9  ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.     8.9  ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.     8.9  ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.     8.9  ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.     8.9  ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n",
            "Q-matrix is updated\n",
            "goal state reached\n",
            "final q-matrix : \n",
            "[[ 0.    -0.1    0.     8.9    7.811]\n",
            " [ 0.    10.     7.811  0.     8.9  ]\n",
            " [ 7.811  0.     0.    10.     8.9  ]\n",
            " [ 0.     0.     0.     0.     0.   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gamma = 0.5\n",
        "\n",
        "#For matrices reward and q_matrix columns are in order (U, D, L, R, N)\n",
        "\n",
        "# here the states are 0, 1, 2, 3 for convenience\n",
        "# 0 is the startinf state\n",
        "# 1 is state to the right of 0\n",
        "# 2 is the snake-pit state\n",
        "# 3 is the treasure(goal state)\n",
        "\n",
        "reward = np.array([[0, -10, 0, -1, -1],\n",
        "         [0, 10, -1, 0, -1],\n",
        "         [-1, 0, 0, 10, -1],\n",
        "         [-1, 0, -10, 0, 10]])\n",
        "\n",
        "q_matrix = np.zeros((4,5))\n",
        "\n",
        "# -1 represent invalid transitions\n",
        "transition_matrix = np.array([[-1, 2, -1, 1, 0],\n",
        "                  [-1, 3, 0, -1, 1],\n",
        "                  [0, -1, -1, 3, 2],\n",
        "                  [1, -1, 2, -1, 3]])\n",
        "\n",
        "# for valid actions\n",
        "# encode up as 0, down as 1, left as 2, right as 3, no action as 4\n",
        "# the rows are the states\n",
        "valid_action = np.array([[1, 3, 4],\n",
        "             [1, 2, 4],\n",
        "             [0, 3, 4],\n",
        "             [0, 2, 4]])\n",
        "\n",
        "for i in range(10): # 10 episodes\n",
        "    start_state = 0\n",
        "    current_state = start_state\n",
        "    while current_state != 3:\n",
        "        action = random.choice(valid_action[current_state])\n",
        "        next_state = transition_matrix[current_state][action]\n",
        "        future_rewards =[]\n",
        "        for action_nxt in valid_action[next_state]:\n",
        "            future_rewards.append(q_matrix[next_state][action_nxt])\n",
        "        q_state = reward[current_state][action] + gamma*max(future_rewards)\n",
        "        q_matrix[current_state][action] = q_state\n",
        "        print(q_matrix)\n",
        "        print('Q-matrix is updated')\n",
        "        current_state = next_state\n",
        "        if current_state == 3:\n",
        "            print('goal state reached')\n",
        "\n",
        "print('final q-matrix : ')\n",
        "print(q_matrix)\n"
      ],
      "metadata": {
        "id": "uk9ckQy7lHY5"
      },
      "id": "uk9ckQy7lHY5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1)\n",
        "상태에 따라서 어떤 액션을 취하면 최대 얼마의 reward를 얻을 수 있는지 분석하고, 이를 계속해서 학습시키면서 미래에 처음부터 가장 합리적인 선택을 할 수 있도록 q-matrix를 사용하기 위해 학습시키는 것이라고 이해했다.\n",
        "\n",
        "### (2)\n",
        "gamma가 작으면 작은 값들은 더 작아지고, 큰 값들은 더 커지는 방향으로 편향성이 커진다. 따라서 agent가 어떤 행동을 하거나 하지 않을 동기가 gamma가 커질 수록 더 커진다고 이해했다."
      ],
      "metadata": {
        "id": "S97Bs8yEkXt1"
      },
      "id": "S97Bs8yEkXt1"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aty6loVOlWaB"
      },
      "id": "Aty6loVOlWaB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}